{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RNN Model for Dopamine Level Prediction\n",
        "\n",
        "This notebook implements a neural network to predict dopamine levels based on red PWM and blue PWM inputs using PyTorch.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Import Necessary Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Jupyter is running on: boslogin05.rc.fas.harvard.edu\n"
          ]
        }
      ],
      "source": [
        "import socket\n",
        "print(\"Jupyter is running on:\", socket.gethostname())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io\n",
        "import h5py\n",
        "import os\n",
        "import tqdm\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2-3: Done on local\n",
        "\n",
        "Local dataset loads and reads faster\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Split into Training and Testing Sets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load directly from saved data\n",
        "\n",
        "save_dir = \"/n/holylabs/LABS/bsabatini_lab/Users/shunnnli/BrainClamp/Data/20250918-W-BiPOLES-DAT-2_g0/dataset\"\n",
        "file_name = \"dataset-200ms-200ms.npz\"\n",
        "\n",
        "# Load the dataset\n",
        "data = np.load(os.path.join(save_dir, file_name))\n",
        "X = data['X']\n",
        "y = data['y']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Data Splitting:\n",
            "X_train shape: (303, 2000, 3)\n",
            "y_train shape: (303, 2000, 3)\n",
            "X_test shape: (76, 2000, 3)\n",
            "y_test shape: (76, 2000, 3)\n"
          ]
        }
      ],
      "source": [
        "train_size = int(len(X) * 0.8)\n",
        "test_size = len(X) - train_size\n",
        "X_train, X_test = X[0:train_size], X[train_size:len(X)]\n",
        "y_train, y_test = y[0:train_size], y[train_size:len(y)]\n",
        "\n",
        "print(\"\\nData Splitting:\")\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: setup TCN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Chomp1d(nn.Module):\n",
        "    \"\"\"Remove future information by chopping off the right padding\"\"\"\n",
        "    def __init__(self, chomp_size):\n",
        "        super(Chomp1d, self).__init__()\n",
        "        self.chomp_size = chomp_size\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x[:, :, :-self.chomp_size].contiguous()\n",
        "\n",
        "\n",
        "class TemporalBlock(nn.Module):\n",
        "    \"\"\"Temporal Convolutional Block with causal padding and residual connection\"\"\"\n",
        "    def __init__(self, n_inputs, n_outputs, kernel_size, stride, dilation, padding, dropout=0.2):\n",
        "        super(TemporalBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(n_inputs, n_outputs, kernel_size,\n",
        "                               stride=stride, padding=padding, dilation=dilation)\n",
        "        self.chomp1 = Chomp1d(padding)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "\n",
        "        self.conv2 = nn.Conv1d(n_outputs, n_outputs, kernel_size,\n",
        "                               stride=stride, padding=padding, dilation=dilation)\n",
        "        self.chomp2 = Chomp1d(padding)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "\n",
        "        self.net = nn.Sequential(self.conv1, self.chomp1, self.relu1, self.dropout1,\n",
        "                                 self.conv2, self.chomp2, self.relu2, self.dropout2)\n",
        "        self.downsample = nn.Conv1d(n_inputs, n_outputs, 1) if n_inputs != n_outputs else None\n",
        "        self.relu = nn.ReLU()\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        self.conv1.weight.data.normal_(0, 0.01)\n",
        "        self.conv2.weight.data.normal_(0, 0.01)\n",
        "        if self.downsample is not None:\n",
        "            self.downsample.weight.data.normal_(0, 0.01)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.net(x)\n",
        "        res = x if self.downsample is None else self.downsample(x)\n",
        "        return self.relu(out + res)\n",
        "\n",
        "\n",
        "class TCNModel(nn.Module):\n",
        "    \"\"\"Temporal Convolutional Network for time series prediction\"\"\"\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size, kernel_size=2, dropout=0.2):\n",
        "        super(TCNModel, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.output_size = output_size\n",
        "        \n",
        "        # Calculate the receptive field\n",
        "        receptive_field = 1\n",
        "        for i in range(num_layers):\n",
        "            receptive_field += (kernel_size - 1) * (2 ** i)\n",
        "        self.receptive_field = receptive_field\n",
        "        \n",
        "        # Input projection layer\n",
        "        # self.input_projection = nn.Linear(input_size, hidden_size)\n",
        "        self.input_projection = nn.Conv1d(input_size, hidden_size, kernel_size=1) if input_size != hidden_size else None\n",
        "        \n",
        "        # Temporal blocks\n",
        "        layers = []\n",
        "        num_channels = [hidden_size] * num_layers\n",
        "        \n",
        "        for i in range(num_layers):\n",
        "            dilation_size = 2 ** i\n",
        "            in_channels = hidden_size if i == 0 else hidden_size\n",
        "            out_channels = num_channels[i]\n",
        "            \n",
        "            layers += [TemporalBlock(in_channels, out_channels, kernel_size, stride=1, dilation=dilation_size,\n",
        "                                     padding=(kernel_size-1) * dilation_size, dropout=dropout)]\n",
        "\n",
        "        self.network = nn.Sequential(*layers)\n",
        "        \n",
        "        # Output layer\n",
        "        self.output_layer = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, seq_len, input_size = x.size()\n",
        "        \n",
        "        # Transpose for TCN: (batch_size, seq_len, input_size) -> (batch_size, input_size, seq_len)\n",
        "        x = x.transpose(1, 2)\n",
        "        \n",
        "        # Input projection\n",
        "        if self.input_projection is not None:\n",
        "            x = self.input_projection(x)\n",
        "        \n",
        "        # TCN processing\n",
        "        x = self.network(x)  # (batch_size, hidden_size, seq_len)\n",
        "        \n",
        "        # Transpose back for output layer\n",
        "        x = x.transpose(1, 2)  # (batch_size, seq_len, hidden_size)\n",
        "        \n",
        "        # Apply output layer to each timestep\n",
        "        out = self.output_layer(x)  # (batch_size, seq_len, output_size)\n",
        "        \n",
        "        return out\n",
        "\n",
        "    def weighted_loss(self, pred, target, gamma=0.999):\n",
        "        dopamine = target[:, :, -1].unsqueeze(-1)\n",
        "        laser_mask = torch.logical_or(target[:, :, 0] > 0.5, target[:, :, 1] > 0.5)\n",
        "        seq_len = pred.shape[1] if pred.dim() > 1 else pred.shape[0]\n",
        "        time_points = torch.arange(seq_len, device=pred.device)\n",
        "\n",
        "        base_loss = nn.MSELoss()(pred, dopamine)\n",
        "        proximity_weight = gamma ** time_points  # 1 for t=0, gamma for t=1, gamma^2 for t=2, ...\n",
        "        laser_weight = 2.0 * laser_mask.unsqueeze(-1) # double the weight of laser events\n",
        "\n",
        "        weighted_loss = base_loss * proximity_weight * laser_weight\n",
        "        return weighted_loss.mean()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# class LSTMModel(nn.Module):\n",
        "#     def __init__(self, input_size, hidden_size, num_layers, output_size, dropout_prob=0.2):\n",
        "#         super(LSTMModel, self).__init__()\n",
        "#         self.hidden_size = hidden_size\n",
        "#         self.num_layers = num_layers\n",
        "        \n",
        "#         # Define the LSTM layer\n",
        "#         # `batch_first=True` means the input tensor shape is (batch, seq, feature)\n",
        "#         self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout_prob)\n",
        "        \n",
        "#         # Define the output layer\n",
        "#         self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         # Initialize hidden and cell states\n",
        "#         h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "#         c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        \n",
        "#         # Forward propagate LSTM\n",
        "#         # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
        "#         out, _ = self.lstm(x, (h0, c0))\n",
        "        \n",
        "#         # Decode the hidden state of the last time step\n",
        "#         out = self.fc(out[:, -1, :])\n",
        "#         return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Build the Model in PyTorch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "# Check GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "TCN Model Architecture:\n",
            "TCNModel(\n",
            "  (input_projection): Conv1d(3, 128, kernel_size=(1,), stride=(1,))\n",
            "  (network): Sequential(\n",
            "    (0): TemporalBlock(\n",
            "      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(2,))\n",
            "      (chomp1): Chomp1d()\n",
            "      (relu1): ReLU()\n",
            "      (dropout1): Dropout(p=0.2, inplace=False)\n",
            "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(2,))\n",
            "      (chomp2): Chomp1d()\n",
            "      (relu2): ReLU()\n",
            "      (dropout2): Dropout(p=0.2, inplace=False)\n",
            "      (net): Sequential(\n",
            "        (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(2,))\n",
            "        (1): Chomp1d()\n",
            "        (2): ReLU()\n",
            "        (3): Dropout(p=0.2, inplace=False)\n",
            "        (4): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(2,))\n",
            "        (5): Chomp1d()\n",
            "        (6): ReLU()\n",
            "        (7): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "      (relu): ReLU()\n",
            "    )\n",
            "    (1): TemporalBlock(\n",
            "      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(2,))\n",
            "      (chomp1): Chomp1d()\n",
            "      (relu1): ReLU()\n",
            "      (dropout1): Dropout(p=0.2, inplace=False)\n",
            "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(2,))\n",
            "      (chomp2): Chomp1d()\n",
            "      (relu2): ReLU()\n",
            "      (dropout2): Dropout(p=0.2, inplace=False)\n",
            "      (net): Sequential(\n",
            "        (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(2,))\n",
            "        (1): Chomp1d()\n",
            "        (2): ReLU()\n",
            "        (3): Dropout(p=0.2, inplace=False)\n",
            "        (4): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(2,))\n",
            "        (5): Chomp1d()\n",
            "        (6): ReLU()\n",
            "        (7): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "      (relu): ReLU()\n",
            "    )\n",
            "    (2): TemporalBlock(\n",
            "      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(4,))\n",
            "      (chomp1): Chomp1d()\n",
            "      (relu1): ReLU()\n",
            "      (dropout1): Dropout(p=0.2, inplace=False)\n",
            "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(4,))\n",
            "      (chomp2): Chomp1d()\n",
            "      (relu2): ReLU()\n",
            "      (dropout2): Dropout(p=0.2, inplace=False)\n",
            "      (net): Sequential(\n",
            "        (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(4,))\n",
            "        (1): Chomp1d()\n",
            "        (2): ReLU()\n",
            "        (3): Dropout(p=0.2, inplace=False)\n",
            "        (4): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(4,))\n",
            "        (5): Chomp1d()\n",
            "        (6): ReLU()\n",
            "        (7): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "      (relu): ReLU()\n",
            "    )\n",
            "    (3): TemporalBlock(\n",
            "      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(8,))\n",
            "      (chomp1): Chomp1d()\n",
            "      (relu1): ReLU()\n",
            "      (dropout1): Dropout(p=0.2, inplace=False)\n",
            "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(8,))\n",
            "      (chomp2): Chomp1d()\n",
            "      (relu2): ReLU()\n",
            "      (dropout2): Dropout(p=0.2, inplace=False)\n",
            "      (net): Sequential(\n",
            "        (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(8,))\n",
            "        (1): Chomp1d()\n",
            "        (2): ReLU()\n",
            "        (3): Dropout(p=0.2, inplace=False)\n",
            "        (4): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(8,))\n",
            "        (5): Chomp1d()\n",
            "        (6): ReLU()\n",
            "        (7): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "      (relu): ReLU()\n",
            "    )\n",
            "    (4): TemporalBlock(\n",
            "      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(16,))\n",
            "      (chomp1): Chomp1d()\n",
            "      (relu1): ReLU()\n",
            "      (dropout1): Dropout(p=0.2, inplace=False)\n",
            "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(16,))\n",
            "      (chomp2): Chomp1d()\n",
            "      (relu2): ReLU()\n",
            "      (dropout2): Dropout(p=0.2, inplace=False)\n",
            "      (net): Sequential(\n",
            "        (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(16,))\n",
            "        (1): Chomp1d()\n",
            "        (2): ReLU()\n",
            "        (3): Dropout(p=0.2, inplace=False)\n",
            "        (4): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(16,))\n",
            "        (5): Chomp1d()\n",
            "        (6): ReLU()\n",
            "        (7): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "      (relu): ReLU()\n",
            "    )\n",
            "    (5): TemporalBlock(\n",
            "      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(32,))\n",
            "      (chomp1): Chomp1d()\n",
            "      (relu1): ReLU()\n",
            "      (dropout1): Dropout(p=0.2, inplace=False)\n",
            "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(32,))\n",
            "      (chomp2): Chomp1d()\n",
            "      (relu2): ReLU()\n",
            "      (dropout2): Dropout(p=0.2, inplace=False)\n",
            "      (net): Sequential(\n",
            "        (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(32,))\n",
            "        (1): Chomp1d()\n",
            "        (2): ReLU()\n",
            "        (3): Dropout(p=0.2, inplace=False)\n",
            "        (4): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(32,))\n",
            "        (5): Chomp1d()\n",
            "        (6): ReLU()\n",
            "        (7): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "      (relu): ReLU()\n",
            "    )\n",
            "    (6): TemporalBlock(\n",
            "      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(64,))\n",
            "      (chomp1): Chomp1d()\n",
            "      (relu1): ReLU()\n",
            "      (dropout1): Dropout(p=0.2, inplace=False)\n",
            "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(64,))\n",
            "      (chomp2): Chomp1d()\n",
            "      (relu2): ReLU()\n",
            "      (dropout2): Dropout(p=0.2, inplace=False)\n",
            "      (net): Sequential(\n",
            "        (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(64,))\n",
            "        (1): Chomp1d()\n",
            "        (2): ReLU()\n",
            "        (3): Dropout(p=0.2, inplace=False)\n",
            "        (4): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(64,))\n",
            "        (5): Chomp1d()\n",
            "        (6): ReLU()\n",
            "        (7): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "      (relu): ReLU()\n",
            "    )\n",
            "    (7): TemporalBlock(\n",
            "      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(256,), dilation=(128,))\n",
            "      (chomp1): Chomp1d()\n",
            "      (relu1): ReLU()\n",
            "      (dropout1): Dropout(p=0.2, inplace=False)\n",
            "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(256,), dilation=(128,))\n",
            "      (chomp2): Chomp1d()\n",
            "      (relu2): ReLU()\n",
            "      (dropout2): Dropout(p=0.2, inplace=False)\n",
            "      (net): Sequential(\n",
            "        (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(256,), dilation=(128,))\n",
            "        (1): Chomp1d()\n",
            "        (2): ReLU()\n",
            "        (3): Dropout(p=0.2, inplace=False)\n",
            "        (4): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(256,), dilation=(128,))\n",
            "        (5): Chomp1d()\n",
            "        (6): ReLU()\n",
            "        (7): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "      (relu): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (output_layer): Linear(in_features=128, out_features=1, bias=True)\n",
            ")\n",
            "\n",
            "TCN Receptive Field: 511\n",
            "Input sequence length: 2000\n",
            "Hidden size: 128\n",
            "Number of layers: 8\n"
          ]
        }
      ],
      "source": [
        "# Model parameters\n",
        "input_size = X_train.shape[2]  # Number of features (3)\n",
        "hidden_size = 128\n",
        "num_layers = 8 \n",
        "output_size = 1\n",
        "\n",
        "# Create TCN model\n",
        "tcn_model = TCNModel(\n",
        "    input_size=input_size, \n",
        "    hidden_size=hidden_size, \n",
        "    num_layers=num_layers,\n",
        "    output_size=output_size, \n",
        "    kernel_size=3,  # TCN kernel size\n",
        "    dropout=0.2\n",
        ")\n",
        "\n",
        "print(\"\\nTCN Model Architecture:\")\n",
        "print(tcn_model)\n",
        "print(f\"\\nTCN Receptive Field: {tcn_model.receptive_field}\")\n",
        "print(f\"Input sequence length: {X_train.shape[1]}\")\n",
        "print(f\"Hidden size: {hidden_size}\")\n",
        "print(f\"Number of layers: {num_layers}\")\n",
        "\n",
        "# Use TCN model\n",
        "model = tcn_model\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Model parameters\n",
        "# input_size = X_train.shape[2]  # Number of features (3)\n",
        "# hidden_size = 50\n",
        "# num_layers = 2 # Corresponds to two stacked LSTM layers\n",
        "# output_size = 1\n",
        "\n",
        "# model = LSTMModel(input_size, hidden_size, num_layers, output_size)\n",
        "# print(\"\\nModel Architecture:\")\n",
        "# print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Train the Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Starting model training...\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[15], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m epoch_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_X, batch_y \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m---> 17\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_X\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     loss \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mweighted_loss(outputs, batch_y, gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.999\u001b[39m)\n\u001b[1;32m     19\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
            "File \u001b[0;32m~/miniconda3/envs/photometryclamp/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/photometryclamp/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "Cell \u001b[0;32mIn[11], line 92\u001b[0m, in \u001b[0;36mTCNModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     89\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_projection(x)\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# TCN processing\u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (batch_size, hidden_size, seq_len)\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# Transpose back for output layer\u001b[39;00m\n\u001b[1;32m     95\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# (batch_size, seq_len, hidden_size)\u001b[39;00m\n",
            "File \u001b[0;32m~/miniconda3/envs/photometryclamp/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/photometryclamp/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[0;32m~/miniconda3/envs/photometryclamp/lib/python3.11/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
            "File \u001b[0;32m~/miniconda3/envs/photometryclamp/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/photometryclamp/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "Cell \u001b[0;32mIn[11], line 40\u001b[0m, in \u001b[0;36mTemporalBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 40\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m     res \u001b[38;5;241m=\u001b[39m x \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownsample \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownsample(x)\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out \u001b[38;5;241m+\u001b[39m res)\n",
            "File \u001b[0;32m~/miniconda3/envs/photometryclamp/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/photometryclamp/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[0;32m~/miniconda3/envs/photometryclamp/lib/python3.11/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
            "File \u001b[0;32m~/miniconda3/envs/photometryclamp/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/photometryclamp/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[0;32m~/miniconda3/envs/photometryclamp/lib/python3.11/site-packages/torch/nn/modules/conv.py:375\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/photometryclamp/lib/python3.11/site-packages/torch/nn/modules/conv.py:370\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(\n\u001b[1;32m    360\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    361\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    369\u001b[0m     )\n\u001b[0;32m--> 370\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Training loop\n",
        "num_epochs = 100\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
        "\n",
        "# Create dataloader for batch training\n",
        "from torch.utils.data import DataLoader\n",
        "train_loader = DataLoader(dataset=(X_train, y_train), batch_size=32, shuffle=True)\n",
        "\n",
        "print(\"\\nStarting model training...\")\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "\n",
        "    for batch_X, batch_y in train_loader:\n",
        "        # Move data to the same device as the model\n",
        "        batch_X = batch_X.to(device)\n",
        "        batch_y = batch_y.to(device)\n",
        "\n",
        "        outputs = model(batch_X)\n",
        "        loss = model.weighted_loss(outputs, batch_y, gamma=0.999)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item() * batch_X.size(0)\n",
        "\n",
        "    avg_loss = epoch_loss / len(train_loader.dataset)\n",
        "    train_losses.append(avg_loss)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_outputs = model(X_test)\n",
        "        val_loss = model.weighted_loss(val_outputs, y_test, gamma=0.999)\n",
        "        val_losses.append(val_loss.item())\n",
        "\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_loss:.4f}, Validation Loss: {val_loss.item():.4f}')\n",
        "\n",
        "print(\"Training complete.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check GPU memory before and after\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU memory allocated: {torch.cuda.memory_allocated()/1e9:.2f} GB\")\n",
        "    print(f\"GPU memory cached: {torch.cuda.memory_reserved()/1e9:.2f} GB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Evaluate and Visualize the Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot training & validation loss values\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(train_losses, label='Train Loss')\n",
        "plt.plot(val_losses, label='Validation Loss')\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(loc='upper right')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make predictions\n",
        "model.eval() # Ensure model is in evaluation mode\n",
        "with torch.no_grad():\n",
        "    train_predict = model(X_train)\n",
        "    test_predict = model(X_test)\n",
        "\n",
        "# Convert tensors to numpy arrays for inverse scaling and plotting\n",
        "train_predict_np = train_predict.numpy()\n",
        "test_predict_np = test_predict.numpy()\n",
        "y_train_np = y_train.numpy()\n",
        "y_test_np = y_test.numpy()\n",
        "\n",
        "# To properly inverse transform, we need a dummy array with the same\n",
        "# number of features as the original scaler.\n",
        "def inverse_transform_predictions(predictions, scaler, n_features):\n",
        "    dummy_array = np.zeros((len(predictions), n_features))\n",
        "    dummy_array[:, 0] = predictions.ravel()\n",
        "    inversed = scaler.inverse_transform(dummy_array)\n",
        "    return inversed[:, 0]\n",
        "\n",
        "train_predict_orig = inverse_transform_predictions(train_predict_np, scaler, input_size)\n",
        "y_train_orig = inverse_transform_predictions(y_train_np, scaler, input_size)\n",
        "test_predict_orig = inverse_transform_predictions(test_predict_np, scaler, input_size)\n",
        "y_test_orig = inverse_transform_predictions(y_test_np, scaler, input_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot the results on the test set\n",
        "fig, axs = plt.subplots(2,1,figsize=(15, 10))\n",
        "axs[0].plot(y_test_orig, color='blue', label='Actual Dopamine Level')\n",
        "axs[0].plot(test_predict_orig, color='red', linestyle='--', label='Predicted Dopamine Level')\n",
        "axs[0].set_title('Dopamine Level Prediction on Test Data')\n",
        "axs[0].set_xlabel('Time Step')\n",
        "axs[0].set_ylabel('Dopamine Level')\n",
        "axs[0].legend()\n",
        "\n",
        "axs[1].plot(y_train_orig, color='blue', label='Actual Dopamine Level')\n",
        "axs[1].plot(train_predict_orig, color='red', linestyle='--', label='Predicted Dopamine Level')\n",
        "axs[1].set_title('Dopamine Level Prediction on Training Data')\n",
        "axs[1].set_xlabel('Time Step')\n",
        "axs[1].set_ylabel('Dopamine Level')\n",
        "axs[1].legend()\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def simulate_input_data(red_laser, blue_laser, input_duration=0.5,\n",
        "                        fs=10000, plot=False, stim_samples=500):\n",
        "    simulate_samples = int(input_duration * fs)\n",
        "    simulated_dopamine = np.random.randn(simulate_samples)\n",
        "    simulated_red_laser = np.zeros(simulate_samples)\n",
        "    simulated_blue_laser = np.zeros(simulate_samples)\n",
        "\n",
        "    # Make red laser pulses (5 samples per pulse) in the last 100ms\n",
        "    if red_laser:\n",
        "        red_laser_start = simulate_samples - stim_samples\n",
        "        for i in range(red_laser_start, simulate_samples,15):\n",
        "            simulated_red_laser[i:i+5] = 1\n",
        "        # add small ramp up of dopamine signal\n",
        "        simulated_dopamine[red_laser_start:simulate_samples] += np.linspace(0, 1, stim_samples)\n",
        "            \n",
        "\n",
        "    if blue_laser:\n",
        "        blue_laser_start = simulate_samples - stim_samples\n",
        "        for i in range(blue_laser_start, simulate_samples,15):\n",
        "            simulated_blue_laser[i:i+5] = 1\n",
        "        # add small ramp up of dopamine signal\n",
        "        simulated_dopamine[blue_laser_start:simulate_samples] -= np.linspace(0, 1, stim_samples)\n",
        "\n",
        "    # low pass filter the dopamine signal\n",
        "    cutoff = 200  # Cutoff frequency in Hz\n",
        "    simulated_dopamine = butter_lowpass_filter(simulated_dopamine.flatten(), cutoff, fs)\n",
        "\n",
        "    if plot:\n",
        "        plt.plot(simulated_dopamine, color='green')\n",
        "        plt.plot(simulated_red_laser, color='red')\n",
        "        plt.plot(simulated_blue_laser, color='blue')\n",
        "        plt.show()\n",
        "\n",
        "    return np.vstack((simulated_red_laser, simulated_blue_laser, simulated_dopamine)).T\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feed in an artificial 500ms data sequence and predict the output\n",
        "\n",
        "# 1. Generate a random 500ms data sequence with no/red/blue laser pulse for last 100ms\n",
        "fake_no_laser = simulate_input_data(red_laser=False, blue_laser=False, input_duration=0.5, fs=10000, plot=False)\n",
        "fake_no_laser_scaled = scaler.transform(fake_no_laser)\n",
        "fake_no_laser_tensor = torch.from_numpy(fake_no_laser).float().unsqueeze(0)\n",
        "fake_red_laser = simulate_input_data(red_laser=True, blue_laser=False, input_duration=0.5, fs=10000, plot=False)\n",
        "fake_red_laser_scaled = scaler.transform(fake_red_laser)\n",
        "fake_red_laser_tensor = torch.from_numpy(fake_red_laser).float().unsqueeze(0)\n",
        "fake_blue_laser = simulate_input_data(red_laser=False, blue_laser=True, input_duration=0.5, fs=10000, plot=False)\n",
        "fake_blue_laser_scaled = scaler.transform(fake_blue_laser)\n",
        "fake_blue_laser_tensor = torch.from_numpy(fake_blue_laser).float().unsqueeze(0)\n",
        "\n",
        "\n",
        "# 2. Predict the output for the future 500ms \n",
        "n_pred_samples = int(0.1 * targetFs)\n",
        "pred_no_laser = torch.zeros((n_pred_samples, 1))\n",
        "pred_red_laser = torch.zeros((n_pred_samples, 1))\n",
        "pred_blue_laser = torch.zeros((n_pred_samples, 1))\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for i in tqdm.tqdm(range(n_pred_samples)):\n",
        "        # Predict the output\n",
        "        no_laser_pred = model(fake_no_laser_tensor).numpy()\n",
        "        red_laser_pred = model(fake_red_laser_tensor).numpy()\n",
        "        blue_laser_pred = model(fake_blue_laser_tensor).numpy()\n",
        "\n",
        "        # Inverse transform the predictions\n",
        "        dopamine_min = scaler.min_[2]  # Third feature (dopamine)\n",
        "        dopamine_scale = scaler.scale_[2]  # Third feature (dopamine)\n",
        "        no_laser_pred_orig = no_laser_pred * dopamine_scale + dopamine_min\n",
        "        red_laser_pred_orig = red_laser_pred * dopamine_scale + dopamine_min\n",
        "        blue_laser_pred_orig = blue_laser_pred * dopamine_scale + dopamine_min\n",
        "\n",
        "        # Store the predictions\n",
        "        pred_no_laser[i] = torch.from_numpy(no_laser_pred_orig)\n",
        "        pred_red_laser[i] = torch.from_numpy(red_laser_pred_orig)\n",
        "        pred_blue_laser[i] = torch.from_numpy(blue_laser_pred_orig)\n",
        "\n",
        "        # shift the time step by 1 and add the new dopamine level\n",
        "        new_sample = [0, 0, pred_no_laser[i].item()]  # Use .item() to get scalar value\n",
        "        new_sample_tensor = torch.tensor(new_sample).unsqueeze(0).unsqueeze(0)  # Shape: (1, 1, 3)\n",
        "        fake_no_laser_tensor = torch.cat((fake_no_laser_tensor[:, 1:, :], new_sample_tensor), dim=1)\n",
        "        fake_red_laser_tensor = torch.cat((fake_red_laser_tensor[:, 1:, :], new_sample_tensor), dim=1)\n",
        "        fake_blue_laser_tensor = torch.cat((fake_blue_laser_tensor[:, 1:, :], new_sample_tensor), dim=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot fake_no_laser_tensor\n",
        "fig, axs = plt.subplots(3,1,figsize=(15, 7))\n",
        "axs[0].plot(fake_no_laser_tensor[:,:,2].squeeze().numpy(), color='green')\n",
        "axs[1].plot(fake_red_laser_tensor[:,:,0].squeeze().numpy(), color='green')\n",
        "axs[2].plot(fake_blue_laser_tensor[:,:,1].squeeze().numpy(), color='green')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3. Plot the results\n",
        "fig, axs = plt.subplots(3,2,figsize=(15, 7))\n",
        "axs[0,0].plot(fake_no_laser[:,0], color='red')\n",
        "axs[0,0].plot(fake_no_laser[:,1], color='blue')\n",
        "axs[0,0].plot(fake_no_laser[:,2], color='green')\n",
        "\n",
        "axs[1,0].plot(fake_red_laser[:,0], color='red')\n",
        "axs[1,0].plot(fake_red_laser[:,1], color='blue')\n",
        "axs[1,0].plot(fake_red_laser[:,2], color='green')\n",
        "\n",
        "axs[2,0].plot(fake_blue_laser[:,0], color='red')\n",
        "axs[2,0].plot(fake_blue_laser[:,1], color='blue')\n",
        "axs[2,0].plot(fake_blue_laser[:,2], color='green')\n",
        "\n",
        "axs[0,1].plot(pred_no_laser, color='gray')\n",
        "axs[1,1].plot(pred_red_laser, color='red')\n",
        "axs[2,1].plot(pred_blue_laser, color='blue')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 9: Save the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the model\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "# Create models directory if it doesn't exist\n",
        "os.makedirs(\"models\", exist_ok=True)\n",
        "\n",
        "# Get today's date as YYYY-MM-DD\n",
        "today_str = datetime.today().strftime('%Y%m%d')\n",
        "model_filename = f\"models/TCN-{today_str}.pt\"\n",
        "\n",
        "# Save the PyTorch model's state_dict\n",
        "torch.save(model.state_dict(), model_filename)\n",
        "\n",
        "print(f\"Model saved to {model_filename}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the model\n",
        "model_filename = \"models/TCN-20251010.pt\"\n",
        "\n",
        "# Model parameters\n",
        "input_size = X_train.shape[2]  # Number of features (3)\n",
        "hidden_size = 128\n",
        "num_layers = 8 \n",
        "output_size = 1\n",
        "\n",
        "# Create TCN model\n",
        "model = TCNModel(\n",
        "    input_size=input_size, \n",
        "    hidden_size=hidden_size, \n",
        "    num_layers=num_layers,\n",
        "    output_size=output_size, \n",
        "    kernel_size=3,  # TCN kernel size\n",
        "    dropout=0.2\n",
        ")\n",
        "\n",
        "model.load_state_dict(torch.load(model_filename))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup a PID controller with RL gain control"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import deque\n",
        "import random\n",
        "\n",
        "class PIDController:\n",
        "    \"\"\"PID Controller with RL-based gain adaptation\"\"\"\n",
        "    \n",
        "    def __init__(self, target_dopamine=0.5, kp_init=1.0, ki_init=0.1, kd_init=0.01):\n",
        "        # Target dopamine level\n",
        "        self.target_dopamine = target_dopamine\n",
        "        \n",
        "        # Initial PID gains\n",
        "        self.kp = kp_init\n",
        "        self.ki = ki_init\n",
        "        self.kd = kd_init\n",
        "        \n",
        "        # PID state variables\n",
        "        self.previous_error = 0.0\n",
        "        self.integral = 0.0\n",
        "        \n",
        "        # Control output limits\n",
        "        self.output_min = -1.0\n",
        "        self.output_max = 1.0\n",
        "        \n",
        "        # History for analysis\n",
        "        self.error_history = []\n",
        "        self.output_history = []\n",
        "        self.gain_history = {'kp': [], 'ki': [], 'kd': []}\n",
        "        \n",
        "    def update(self, current_dopamine, dt=1.0):\n",
        "        \"\"\"Update PID controller with current dopamine reading\"\"\"\n",
        "        # Calculate error\n",
        "        error = self.target_dopamine - current_dopamine\n",
        "        \n",
        "        # Proportional term\n",
        "        proportional = self.kp * error\n",
        "        \n",
        "        # Integral term\n",
        "        self.integral += error * dt\n",
        "        integral_term = self.ki * self.integral\n",
        "        \n",
        "        # Derivative term\n",
        "        derivative = (error - self.previous_error) / dt\n",
        "        derivative_term = self.kd * derivative\n",
        "        \n",
        "        # Calculate PID output\n",
        "        output = proportional + integral_term + derivative_term\n",
        "        \n",
        "        # Apply output limits\n",
        "        output = np.clip(output, self.output_min, self.output_max)\n",
        "        \n",
        "        # Update previous error\n",
        "        self.previous_error = error\n",
        "        \n",
        "        # Store history\n",
        "        self.error_history.append(error)\n",
        "        self.output_history.append(output)\n",
        "        self.gain_history['kp'].append(self.kp)\n",
        "        self.gain_history['ki'].append(self.ki)\n",
        "        self.gain_history['kd'].append(self.kd)\n",
        "        \n",
        "        return output\n",
        "    \n",
        "    def update_gains(self, delta_kp, delta_ki, delta_kd):\n",
        "        \"\"\"Update PID gains with constraints\"\"\"\n",
        "        # Update gains with learning rates\n",
        "        lr_p = 0.01\n",
        "        lr_i = 0.005\n",
        "        lr_d = 0.001\n",
        "        \n",
        "        self.kp += lr_p * delta_kp\n",
        "        self.ki += lr_i * delta_ki\n",
        "        self.kd += lr_d * delta_kd\n",
        "        \n",
        "        # Apply constraints to keep gains positive and reasonable\n",
        "        self.kp = np.clip(self.kp, 0.1, 10.0)\n",
        "        self.ki = np.clip(self.ki, 0.0, 2.0)\n",
        "        self.kd = np.clip(self.kd, 0.0, 1.0)\n",
        "    \n",
        "    def reset(self):\n",
        "        \"\"\"Reset PID controller state\"\"\"\n",
        "        self.previous_error = 0.0\n",
        "        self.integral = 0.0\n",
        "        self.error_history = []\n",
        "        self.output_history = []\n",
        "        self.gain_history = {'kp': [], 'ki': [], 'kd': []}\n",
        "\n",
        "\n",
        "class RLGainOptimizer:\n",
        "    \"\"\"Reinforcement Learning optimizer for PID gains\"\"\"\n",
        "    \n",
        "    def __init__(self, state_dim=4, action_dim=3, learning_rate=0.001):\n",
        "        self.state_dim = state_dim  # [error, error_history, integral, derivative]\n",
        "        self.action_dim = action_dim  # [delta_kp, delta_ki, delta_kd]\n",
        "        \n",
        "        # Neural network for policy\n",
        "        self.policy_net = nn.Sequential(\n",
        "            nn.Linear(state_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, action_dim),\n",
        "            nn.Tanh()  # Output between -1 and 1\n",
        "        )\n",
        "        \n",
        "        # Optimizer\n",
        "        self.optimizer = optim.Adam(self.policy_net.parameters(), lr=learning_rate)\n",
        "        \n",
        "        # Experience replay buffer\n",
        "        self.memory = deque(maxlen=10000)\n",
        "        self.batch_size = 32\n",
        "        \n",
        "        # Hyperparameters\n",
        "        self.gamma = 0.99  # Discount factor\n",
        "        self.epsilon = 0.1  # Exploration rate\n",
        "        self.epsilon_decay = 0.995\n",
        "        self.epsilon_min = 0.01\n",
        "        \n",
        "    def get_state(self, pid_controller):\n",
        "        \"\"\"Extract state from PID controller\"\"\"\n",
        "        if len(pid_controller.error_history) < 2:\n",
        "            return np.zeros(self.state_dim)\n",
        "        \n",
        "        # Current error\n",
        "        current_error = pid_controller.error_history[-1]\n",
        "        \n",
        "        # Error trend (average of last 5 errors)\n",
        "        error_trend = np.mean(pid_controller.error_history[-5:]) if len(pid_controller.error_history) >= 5 else current_error\n",
        "        \n",
        "        # Integral value\n",
        "        integral = pid_controller.integral\n",
        "        \n",
        "        # Derivative (approximate)\n",
        "        derivative = 0.0\n",
        "        if len(pid_controller.error_history) >= 2:\n",
        "            derivative = pid_controller.error_history[-1] - pid_controller.error_history[-2]\n",
        "        \n",
        "        return np.array([current_error, error_trend, integral, derivative])\n",
        "    \n",
        "    def select_action(self, state):\n",
        "        \"\"\"Select action using epsilon-greedy policy\"\"\"\n",
        "        if np.random.random() < self.epsilon:\n",
        "            # Random action for exploration\n",
        "            return np.random.uniform(-1, 1, self.action_dim)\n",
        "        else:\n",
        "            # Greedy action from policy network\n",
        "            state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
        "            with torch.no_grad():\n",
        "                action = self.policy_net(state_tensor).squeeze().numpy()\n",
        "            return action\n",
        "    \n",
        "    def remember(self, state, action, reward, next_state, done):\n",
        "        \"\"\"Store experience in replay buffer\"\"\"\n",
        "        self.memory.append((state, action, reward, next_state, done))\n",
        "    \n",
        "    def replay(self):\n",
        "        \"\"\"Train the policy network using experience replay\"\"\"\n",
        "        if len(self.memory) < self.batch_size:\n",
        "            return\n",
        "        \n",
        "        # Sample batch from memory\n",
        "        batch = random.sample(self.memory, self.batch_size)\n",
        "        states = torch.FloatTensor([e[0] for e in batch])\n",
        "        actions = torch.FloatTensor([e[1] for e in batch])\n",
        "        rewards = torch.FloatTensor([e[2] for e in batch])\n",
        "        next_states = torch.FloatTensor([e[3] for e in batch])\n",
        "        \n",
        "        # Compute current Q values\n",
        "        current_q_values = self.policy_net(states)\n",
        "        \n",
        "        # Compute target Q values (simplified - using immediate reward)\n",
        "        target_q_values = rewards.unsqueeze(1).expand_as(current_q_values)\n",
        "        \n",
        "        # Compute loss (MSE between current and target Q values)\n",
        "        loss = nn.MSELoss()(current_q_values, target_q_values)\n",
        "        \n",
        "        # Optimize\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "        \n",
        "        # Decay epsilon\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.epsilon_decay\n",
        "\n",
        "\n",
        "def simulate_dopamine_clamping_with_rl_pid(num_steps=1000, target_dopamine=0.5):\n",
        "    \"\"\"Simulate dopamine clamping with RL-optimized PID controller\"\"\"\n",
        "    \n",
        "    # Initialize PID controller and RL optimizer\n",
        "    pid = PIDController(target_dopamine=target_dopamine)\n",
        "    rl_optimizer = RLGainOptimizer()\n",
        "    \n",
        "    # Simulation parameters\n",
        "    dt = 0.1\n",
        "    current_dopamine = 0.3  # Initial dopamine level\n",
        "    \n",
        "    # System dynamics (simplified dopamine dynamics)\n",
        "    dopamine_dynamics = {\n",
        "        'baseline': 0.3,\n",
        "        'time_constant': 2.0,\n",
        "        'noise_std': 0.05\n",
        "    }\n",
        "    \n",
        "    # Storage for results\n",
        "    results = {\n",
        "        'time': [],\n",
        "        'dopamine': [],\n",
        "        'target': [],\n",
        "        'control_output': [],\n",
        "        'error': [],\n",
        "        'kp': [],\n",
        "        'ki': [],\n",
        "        'kd': []\n",
        "    }\n",
        "    \n",
        "    print(\"Starting dopamine clamping simulation with RL-PID...\")\n",
        "    \n",
        "    for step in range(num_steps):\n",
        "        current_time = step * dt\n",
        "        \n",
        "        # Get PID control output\n",
        "        control_output = pid.update(current_dopamine, dt)\n",
        "        \n",
        "        # Simulate dopamine dynamics (simplified)\n",
        "        # Dopamine responds to control input with some dynamics\n",
        "        dopamine_change = (dopamine_dynamics['baseline'] + control_output * 0.5 - current_dopamine) / dopamine_dynamics['time_constant']\n",
        "        current_dopamine += dopamine_change * dt\n",
        "        \n",
        "        # Add noise\n",
        "        current_dopamine += np.random.normal(0, dopamine_dynamics['noise_std'])\n",
        "        \n",
        "        # Ensure dopamine stays in reasonable range\n",
        "        current_dopamine = np.clip(current_dopamine, 0.0, 1.0)\n",
        "        \n",
        "        # Calculate reward (negative squared error)\n",
        "        error = target_dopamine - current_dopamine\n",
        "        reward = -(error ** 2)\n",
        "        \n",
        "        # Get current state\n",
        "        current_state = rl_optimizer.get_state(pid)\n",
        "        \n",
        "        # Select action and update gains (every 10 steps)\n",
        "        if step % 10 == 0 and step > 0:\n",
        "            action = rl_optimizer.select_action(current_state)\n",
        "            pid.update_gains(action[0], action[1], action[2])\n",
        "            \n",
        "            # Get next state\n",
        "            next_state = rl_optimizer.get_state(pid)\n",
        "            \n",
        "            # Store experience\n",
        "            rl_optimizer.remember(current_state, action, reward, next_state, False)\n",
        "            \n",
        "            # Train the RL agent\n",
        "            rl_optimizer.replay()\n",
        "        \n",
        "        # Store results\n",
        "        results['time'].append(current_time)\n",
        "        results['dopamine'].append(current_dopamine)\n",
        "        results['target'].append(target_dopamine)\n",
        "        results['control_output'].append(control_output)\n",
        "        results['error'].append(error)\n",
        "        results['kp'].append(pid.kp)\n",
        "        results['ki'].append(pid.ki)\n",
        "        results['kd'].append(pid.kd)\n",
        "        \n",
        "        # Print progress\n",
        "        if step % 100 == 0:\n",
        "            print(f\"Step {step}: Dopamine={current_dopamine:.3f}, Error={error:.3f}, \"\n",
        "                  f\"Gains: Kp={pid.kp:.3f}, Ki={pid.ki:.3f}, Kd={pid.kd:.3f}\")\n",
        "    \n",
        "    return results, pid, rl_optimizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run the RL-PID simulation\n",
        "results, pid_controller, rl_optimizer = simulate_dopamine_clamping_with_rl_pid(\n",
        "    num_steps=2000, \n",
        "    target_dopamine=0.6\n",
        ")\n",
        "\n",
        "print(f\"\\nSimulation completed!\")\n",
        "print(f\"Final gains: Kp={pid_controller.kp:.3f}, Ki={pid_controller.ki:.3f}, Kd={pid_controller.kd:.3f}\")\n",
        "\n",
        "# Calculate performance metrics\n",
        "final_error = np.mean(np.abs(results['error'][-100:]))  # Mean absolute error in last 100 steps\n",
        "rmse = np.sqrt(np.mean(np.array(results['error'])**2))  # Root mean square error\n",
        "print(f\"Final MAE (last 100 steps): {final_error:.4f}\")\n",
        "print(f\"Overall RMSE: {rmse:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize the RL-PID controller performance\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "# Plot 1: Dopamine level and target\n",
        "axes[0, 0].plot(results['time'], results['dopamine'], label='Actual Dopamine', alpha=0.8)\n",
        "axes[0, 0].plot(results['time'], results['target'], label='Target Dopamine', linestyle='--', color='red')\n",
        "axes[0, 0].set_xlabel('Time (s)')\n",
        "axes[0, 0].set_ylabel('Dopamine Level')\n",
        "axes[0, 0].set_title('Dopamine Clamping Performance')\n",
        "axes[0, 0].legend()\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 2: Control output\n",
        "axes[0, 1].plot(results['time'], results['control_output'], label='Control Output', color='green')\n",
        "axes[0, 1].set_xlabel('Time (s)')\n",
        "axes[0, 1].set_ylabel('Control Output')\n",
        "axes[0, 1].set_title('PID Control Output')\n",
        "axes[0, 1].legend()\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 3: Error over time\n",
        "axes[1, 0].plot(results['time'], results['error'], label='Control Error', color='orange')\n",
        "axes[1, 0].axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
        "axes[1, 0].set_xlabel('Time (s)')\n",
        "axes[1, 0].set_ylabel('Error (Target - Actual)')\n",
        "axes[1, 0].set_title('Control Error Over Time')\n",
        "axes[1, 0].legend()\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 4: PID gains evolution\n",
        "axes[1, 1].plot(results['time'], results['kp'], label='Kp (Proportional)', linewidth=2)\n",
        "axes[1, 1].plot(results['time'], results['ki'], label='Ki (Integral)', linewidth=2)\n",
        "axes[1, 1].plot(results['time'], results['kd'], label='Kd (Derivative)', linewidth=2)\n",
        "axes[1, 1].set_xlabel('Time (s)')\n",
        "axes[1, 1].set_ylabel('Gain Value')\n",
        "axes[1, 1].set_title('RL-Optimized PID Gains Evolution')\n",
        "axes[1, 1].legend()\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Integration with TCN Model for Real-time Dopamine Prediction and Control\n",
        "def integrate_tcn_with_pid_controller(model, pid_controller, rl_optimizer, data_sequence, target_dopamine=0.6):\n",
        "    \"\"\"\n",
        "    Integrate TCN model predictions with PID controller for real-time dopamine clamping\n",
        "    \"\"\"\n",
        "    print(\"Running integrated TCN-PID dopamine clamping...\")\n",
        "    \n",
        "    # Set model to evaluation mode\n",
        "    model.eval()\n",
        "    \n",
        "    results = {\n",
        "        'time': [],\n",
        "        'predicted_dopamine': [],\n",
        "        'actual_dopamine': [],\n",
        "        'target': [],\n",
        "        'control_output': [],\n",
        "        'error': [],\n",
        "        'kp': [],\n",
        "        'ki': [],\n",
        "        'kd': []\n",
        "    }\n",
        "    \n",
        "    # Use the last part of the test data for simulation\n",
        "    sequence_length = model.receptive_field\n",
        "    start_idx = len(data_sequence) - 1000  # Use last 1000 points\n",
        "    \n",
        "    current_dopamine = data_sequence[start_idx, 0]  # Start with actual dopamine level\n",
        "    \n",
        "    for i in range(1000):  # Simulate 1000 steps\n",
        "        current_idx = start_idx + i\n",
        "        current_time = i * 0.1\n",
        "        \n",
        "        # Get input sequence for TCN model\n",
        "        if current_idx >= sequence_length:\n",
        "            input_seq = data_sequence[current_idx - sequence_length:current_idx, :]\n",
        "            input_tensor = torch.FloatTensor(input_seq).unsqueeze(0)  # Add batch dimension\n",
        "            \n",
        "            # Get TCN prediction\n",
        "            with torch.no_grad():\n",
        "                predicted_dopamine = model(input_tensor).item()\n",
        "        else:\n",
        "            predicted_dopamine = current_dopamine\n",
        "        \n",
        "        # Use TCN prediction for PID control\n",
        "        control_output = pid_controller.update(predicted_dopamine, dt=0.1)\n",
        "        \n",
        "        # Simulate actual dopamine response (with some dynamics)\n",
        "        actual_dopamine = data_sequence[current_idx, 0] if current_idx < len(data_sequence) else current_dopamine\n",
        "        \n",
        "        # Add some realistic dynamics\n",
        "        dopamine_change = (actual_dopamine + control_output * 0.3 - current_dopamine) / 1.5\n",
        "        current_dopamine += dopamine_change * 0.1\n",
        "        current_dopamine = np.clip(current_dopamine, 0.0, 1.0)\n",
        "        \n",
        "        # Calculate reward and update RL agent (every 10 steps)\n",
        "        error = target_dopamine - current_dopamine\n",
        "        reward = -(error ** 2)\n",
        "        \n",
        "        if i % 10 == 0 and i > 0:\n",
        "            current_state = rl_optimizer.get_state(pid_controller)\n",
        "            action = rl_optimizer.select_action(current_state)\n",
        "            pid_controller.update_gains(action[0], action[1], action[2])\n",
        "            \n",
        "            next_state = rl_optimizer.get_state(pid_controller)\n",
        "            rl_optimizer.remember(current_state, action, reward, next_state, False)\n",
        "            rl_optimizer.replay()\n",
        "        \n",
        "        # Store results\n",
        "        results['time'].append(current_time)\n",
        "        results['predicted_dopamine'].append(predicted_dopamine)\n",
        "        results['actual_dopamine'].append(current_dopamine)\n",
        "        results['target'].append(target_dopamine)\n",
        "        results['control_output'].append(control_output)\n",
        "        results['error'].append(error)\n",
        "        results['kp'].append(pid_controller.kp)\n",
        "        results['ki'].append(pid_controller.ki)\n",
        "        results['kd'].append(pid_controller.kd)\n",
        "        \n",
        "        if i % 100 == 0:\n",
        "            print(f\"Step {i}: Predicted={predicted_dopamine:.3f}, Actual={current_dopamine:.3f}, \"\n",
        "                  f\"Error={error:.3f}, Gains: Kp={pid_controller.kp:.3f}, Ki={pid_controller.ki:.3f}, Kd={pid_controller.kd:.3f}\")\n",
        "    \n",
        "    return results\n",
        "\n",
        "# Run integrated TCN-PID simulation\n",
        "print(\"\\\\n\" + \"=\"*60)\n",
        "print(\"INTEGRATED TCN-PID DOPAMINE CLAMPING SIMULATION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Reset PID controller for fresh start\n",
        "pid_controller.reset()\n",
        "rl_optimizer.epsilon = 0.1  # Reset exploration\n",
        "\n",
        "# Run the integrated simulation\n",
        "integrated_results = integrate_tcn_with_pid_controller(\n",
        "    model, \n",
        "    pid_controller, \n",
        "    rl_optimizer, \n",
        "    scaled_data,  # Use the scaled data from earlier\n",
        "    target_dopamine=0.6\n",
        ")\n",
        "\n",
        "print(f\"\\\\nIntegrated simulation completed!\")\n",
        "print(f\"Final gains: Kp={pid_controller.kp:.3f}, Ki={pid_controller.ki:.3f}, Kd={pid_controller.kd:.3f}\")\n",
        "\n",
        "# Calculate integrated performance metrics\n",
        "final_error_integrated = np.mean(np.abs(integrated_results['error'][-100:]))\n",
        "rmse_integrated = np.sqrt(np.mean(np.array(integrated_results['error'])**2))\n",
        "print(f\"Final MAE (last 100 steps): {final_error_integrated:.4f}\")\n",
        "print(f\"Overall RMSE: {rmse_integrated:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize the integrated TCN-PID controller performance\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "# Plot 1: Predicted vs Actual dopamine with target\n",
        "axes[0, 0].plot(integrated_results['time'], integrated_results['predicted_dopamine'], \n",
        "                label='TCN Predicted', alpha=0.7, color='blue')\n",
        "axes[0, 0].plot(integrated_results['time'], integrated_results['actual_dopamine'], \n",
        "                label='Actual Dopamine', alpha=0.8, color='green')\n",
        "axes[0, 0].plot(integrated_results['time'], integrated_results['target'], \n",
        "                label='Target', linestyle='--', color='red')\n",
        "axes[0, 0].set_xlabel('Time (s)')\n",
        "axes[0, 0].set_ylabel('Dopamine Level')\n",
        "axes[0, 0].set_title('TCN-PID Integrated Dopamine Clamping')\n",
        "axes[0, 0].legend()\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 2: Control output\n",
        "axes[0, 1].plot(integrated_results['time'], integrated_results['control_output'], \n",
        "                label='Control Output', color='purple')\n",
        "axes[0, 1].set_xlabel('Time (s)')\n",
        "axes[0, 1].set_ylabel('Control Output')\n",
        "axes[0, 1].set_title('PID Control Output (TCN-Integrated)')\n",
        "axes[0, 1].legend()\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 3: Prediction error vs control error\n",
        "prediction_error = np.array(integrated_results['predicted_dopamine']) - np.array(integrated_results['actual_dopamine'])\n",
        "axes[1, 0].plot(integrated_results['time'], prediction_error, \n",
        "                label='Prediction Error', color='orange', alpha=0.7)\n",
        "axes[1, 0].plot(integrated_results['time'], integrated_results['error'], \n",
        "                label='Control Error', color='red', alpha=0.7)\n",
        "axes[1, 0].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
        "axes[1, 0].set_xlabel('Time (s)')\n",
        "axes[1, 0].set_ylabel('Error')\n",
        "axes[1, 0].set_title('Prediction Error vs Control Error')\n",
        "axes[1, 0].legend()\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 4: RL-optimized PID gains evolution\n",
        "axes[1, 1].plot(integrated_results['time'], integrated_results['kp'], \n",
        "                label='Kp (Proportional)', linewidth=2)\n",
        "axes[1, 1].plot(integrated_results['time'], integrated_results['ki'], \n",
        "                label='Ki (Integral)', linewidth=2)\n",
        "axes[1, 1].plot(integrated_results['time'], integrated_results['kd'], \n",
        "                label='Kd (Derivative)', linewidth=2)\n",
        "axes[1, 1].set_xlabel('Time (s)')\n",
        "axes[1, 1].set_ylabel('Gain Value')\n",
        "axes[1, 1].set_title('RL-Optimized PID Gains (TCN-Integrated)')\n",
        "axes[1, 1].legend()\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print summary statistics\n",
        "print(\"\\\\n\" + \"=\"*60)\n",
        "print(\"SUMMARY STATISTICS\")\n",
        "print(\"=\"*60)\n",
        "print(f\"TCN Model Receptive Field: {model.receptive_field} timesteps\")\n",
        "print(f\"Final PID Gains: Kp={pid_controller.kp:.3f}, Ki={pid_controller.ki:.3f}, Kd={pid_controller.kd:.3f}\")\n",
        "print(f\"Final Control Error (MAE): {final_error_integrated:.4f}\")\n",
        "print(f\"Overall Control Error (RMSE): {rmse_integrated:.4f}\")\n",
        "print(f\"Average Prediction Error: {np.mean(np.abs(prediction_error)):.4f}\")\n",
        "print(f\"Exploration Rate (final): {rl_optimizer.epsilon:.3f}\")\n",
        "print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
